{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import modules\n",
    "import os\n",
    "import requests\n",
    "import pandas as pd\n",
    "from bs4 import BeautifulSoup\n",
    "import csv\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a dictionary of URLs for each position group\n",
    "\n",
    "url_dict = {\n",
    "    \"QB\": \"https://www.fantasypros.com/nfl/projections/qb.php?week=draft\",\n",
    "    \"RB\": \"https://www.fantasypros.com/nfl/projections/rb.php?week=draft&scoring=PPR&week=draft\",\n",
    "    \"WR\": \"https://www.fantasypros.com/nfl/projections/wr.php?week=draft&scoring=PPR&week=draft\",\n",
    "    \"TE\": \"https://www.fantasypros.com/nfl/projections/te.php?week=draft&scoring=PPR&week=draft\",\n",
    "    \"FLEX\": \"https://www.fantasypros.com/nfl/projections/flex.php?week=draft&scoring=PPR&week=draft\",\n",
    "    \"K\": \"https://www.fantasypros.com/nfl/projections/k.php?week=draft\",\n",
    "    \"DEF\": \"https://www.fantasypros.com/nfl/projections/dst.php?week=draft\",\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data from QB (https://www.fantasypros.com/nfl/projections/qb.php?week=draft) saved to data/scraped/QB_projections.csv\n",
      "Data from RB (https://www.fantasypros.com/nfl/projections/rb.php?week=draft&scoring=PPR&week=draft) saved to data/scraped/RB_projections.csv\n",
      "Data from WR (https://www.fantasypros.com/nfl/projections/wr.php?week=draft&scoring=PPR&week=draft) saved to data/scraped/WR_projections.csv\n",
      "Data from TE (https://www.fantasypros.com/nfl/projections/te.php?week=draft&scoring=PPR&week=draft) saved to data/scraped/TE_projections.csv\n",
      "Data from FLEX (https://www.fantasypros.com/nfl/projections/flex.php?week=draft&scoring=PPR&week=draft) saved to data/scraped/FLEX_projections.csv\n",
      "Data from K (https://www.fantasypros.com/nfl/projections/k.php?week=draft) saved to data/scraped/K_projections.csv\n",
      "Data from DEF (https://www.fantasypros.com/nfl/projections/dst.php?week=draft) saved to data/scraped/DEF_projections.csv\n",
      "Scraping and data saving completed.\n"
     ]
    }
   ],
   "source": [
    "# Step 2: Loop through each key-value pair in the dictionary\n",
    "for name, url in url_dict.items():\n",
    "    response = requests.get(url)\n",
    "    soup = BeautifulSoup(response.text, \"html.parser\")\n",
    "\n",
    "    # Example: Locate and extract data from a table (customize this as needed)\n",
    "    table = soup.find(\"table\")\n",
    "\n",
    "    if table:\n",
    "        headers = [header.get_text().strip() for header in table.find_all(\"th\")]\n",
    "        rows = []\n",
    "        for row in table.find_all(\"tr\"):\n",
    "            cells = [cell.get_text().strip() for cell in row.find_all(\"td\")]\n",
    "            if cells:  # Only append non-empty rows\n",
    "                rows.append(cells)\n",
    "\n",
    "        # Combine headers and rows into a DataFrame\n",
    "        df = pd.DataFrame(rows, columns=headers)\n",
    "\n",
    "        # Step 3: Save each DataFrame to a separate CSV file with the variable name\n",
    "        filename = os.path.join(\"data/scraped\", f\"{name}_projections.csv\")\n",
    "        df.to_csv(filename, index=False)\n",
    "\n",
    "        print(f\"Data from {name} ({url}) saved to {filename}\")\n",
    "\n",
    "print(\"Scraping and data saving completed.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data from QB_projections saved to data/clean/QB_projections_clean.csv\n",
      "Data from RB_projections saved to data/clean/RB_projections_clean.csv\n",
      "Data from WR_projections saved to data/clean/WR_projections_clean.csv\n",
      "Data from TE_projections saved to data/clean/TE_projections_clean.csv\n",
      "Data from FLEX_projections saved to data/clean/FLEX_projections_clean.csv\n",
      "Data from K_projections saved to data/clean/K_projections_clean.csv\n",
      "Data from DEF_projections saved to data/clean/DEF_projections_clean.csv\n",
      "Data cleaning completed.\n"
     ]
    }
   ],
   "source": [
    "# Clean the data so it can be manipulated\n",
    "\n",
    "# Some of the positions have an extra row of column headers that need to be deleted\n",
    "\n",
    "clean_files = [\n",
    "    \"QB_projections\",\n",
    "    \"RB_projections\",\n",
    "    \"WR_projections\",\n",
    "    \"TE_projections\",\n",
    "    \"FLEX_projections\",\n",
    "    \"K_projections\",\n",
    "    \"DEF_projections\",\n",
    "]\n",
    "\n",
    "for file in clean_files:\n",
    "    df = pd.read_csv(f\"data/scraped/{file}.csv\")\n",
    "\n",
    "    # Make sure all columns after the 'Player' column are numerical\n",
    "    df.iloc[:, 2:] = (\n",
    "        df.iloc[:, 2:]\n",
    "        .replace({\",\": \"\"}, regex=True)\n",
    "        .apply(pd.to_numeric, errors=\"coerce\")\n",
    "        .astype(float)\n",
    "    )\n",
    "\n",
    "    if file == \"RB_projections\":\n",
    "        df = df[1:]\n",
    "        df = df.rename(\n",
    "            columns={\n",
    "                \"YDS\": \"RUSH_YDS\",\n",
    "                \"TDS\": \"RUSH_TDS\",\n",
    "                \"YDS.1\": \"REC_YDS\",\n",
    "                \"TDS.1\": \"REC_TDS\",\n",
    "            }\n",
    "        )\n",
    "    elif file == \"WR_projections\":\n",
    "        df = df[1:]\n",
    "        df = df.rename(\n",
    "            columns={\n",
    "                \"YDS\": \"REC_YDS\",\n",
    "                \"TDS\": \"REC_TDS\",\n",
    "                \"YDS.1\": \"RUSH_YDS\",\n",
    "                \"TDS.1\": \"RUSH_TDS\",\n",
    "            }\n",
    "        )\n",
    "    elif file == \"TE_projections\":\n",
    "        df = df[1:]\n",
    "        df = df.rename(columns={\"YDS\": \"REC_YDS\", \"TDS\": \"REC_TDS\"})\n",
    "\n",
    "    elif file == \"QB_projections\":\n",
    "        df = df[1:]\n",
    "        df = df.rename(columns={\"YDS\": \"PASS_YDS\", \"TDS\": \"PASS_TDS\"})\n",
    "\n",
    "    elif file == \"FLEX_projections\":\n",
    "        df = df[1:]\n",
    "        df = df.rename(\n",
    "            columns={\n",
    "                \"YDS\": \"RUSH_YDS\",\n",
    "                \"TDS\": \"RUSH_TDS\",\n",
    "                \"YDS.1\": \"REC_YDS\",\n",
    "                \"TDS.1\": \"REC_TDS\",\n",
    "            }\n",
    "        )\n",
    "        df[\"POS\"] = df[\"POS\"].astype(str).apply(lambda x: re.sub(r\"[^a-zA-Z]\", \"\", x))\n",
    "\n",
    "    # Save cleaned files to the clean subdirectory\n",
    "    filename = os.path.join(\"data/clean\", f\"{file}_clean.csv\")\n",
    "    df.to_csv(filename, index=False)\n",
    "\n",
    "    print(f\"Data from {file} saved to {filename}\")\n",
    "\n",
    "print(\"Data cleaning completed.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Player      object\n",
      "SACK       float64\n",
      "INT        float64\n",
      "FR         float64\n",
      "FF         float64\n",
      "TD         float64\n",
      "SAFETY     float64\n",
      "PA         float64\n",
      "YDS AGN    float64\n",
      "FPTS       float64\n",
      "dtype: object\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Player</th>\n",
       "      <th>SACK</th>\n",
       "      <th>INT</th>\n",
       "      <th>FR</th>\n",
       "      <th>FF</th>\n",
       "      <th>TD</th>\n",
       "      <th>SAFETY</th>\n",
       "      <th>PA</th>\n",
       "      <th>YDS AGN</th>\n",
       "      <th>FPTS</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Dallas Cowboys</td>\n",
       "      <td>50.1</td>\n",
       "      <td>14.2</td>\n",
       "      <td>10.9</td>\n",
       "      <td>16.7</td>\n",
       "      <td>3.1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>347.5</td>\n",
       "      <td>5446.7</td>\n",
       "      <td>118.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Baltimore Ravens</td>\n",
       "      <td>51.1</td>\n",
       "      <td>14.2</td>\n",
       "      <td>11.0</td>\n",
       "      <td>16.5</td>\n",
       "      <td>2.7</td>\n",
       "      <td>0.0</td>\n",
       "      <td>323.9</td>\n",
       "      <td>5261.9</td>\n",
       "      <td>117.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>New York Jets</td>\n",
       "      <td>47.9</td>\n",
       "      <td>14.5</td>\n",
       "      <td>9.7</td>\n",
       "      <td>15.5</td>\n",
       "      <td>2.8</td>\n",
       "      <td>1.0</td>\n",
       "      <td>339.6</td>\n",
       "      <td>5162.8</td>\n",
       "      <td>115.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Houston Texans</td>\n",
       "      <td>49.3</td>\n",
       "      <td>13.3</td>\n",
       "      <td>10.7</td>\n",
       "      <td>15.2</td>\n",
       "      <td>2.4</td>\n",
       "      <td>0.5</td>\n",
       "      <td>392.9</td>\n",
       "      <td>5696.1</td>\n",
       "      <td>112.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Philadelphia Eagles</td>\n",
       "      <td>51.0</td>\n",
       "      <td>13.1</td>\n",
       "      <td>10.2</td>\n",
       "      <td>15.2</td>\n",
       "      <td>2.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>382.4</td>\n",
       "      <td>5572.7</td>\n",
       "      <td>112.4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                Player  SACK   INT    FR    FF   TD  SAFETY     PA  YDS AGN  \\\n",
       "0       Dallas Cowboys  50.1  14.2  10.9  16.7  3.1     0.0  347.5   5446.7   \n",
       "1     Baltimore Ravens  51.1  14.2  11.0  16.5  2.7     0.0  323.9   5261.9   \n",
       "2        New York Jets  47.9  14.5   9.7  15.5  2.8     1.0  339.6   5162.8   \n",
       "3       Houston Texans  49.3  13.3  10.7  15.2  2.4     0.5  392.9   5696.1   \n",
       "4  Philadelphia Eagles  51.0  13.1  10.2  15.2  2.5     0.0  382.4   5572.7   \n",
       "\n",
       "    FPTS  \n",
       "0  118.9  \n",
       "1  117.4  \n",
       "2  115.2  \n",
       "3  112.4  \n",
       "4  112.4  "
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(\"data/clean/DEF_projections_clean.csv\")\n",
    "print(df.dtypes)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # URLs to scrape from\n",
    "\n",
    "# QB = \"https://www.fantasypros.com/nfl/projections/qb.php?week=draft\"\n",
    "# RB = \"https://www.fantasypros.com/nfl/projections/rb.php?week=draft&scoring=PPR&week=draft\"\n",
    "# WR = \"https://www.fantasypros.com/nfl/projections/wr.php?week=draft&scoring=PPR&week=draft\"\n",
    "# TE = \"https://www.fantasypros.com/nfl/projections/te.php?week=draft&scoring=PPR&week=draft\"\n",
    "# FLEX = \"https://www.fantasypros.com/nfl/projections/flex.php?week=draft&scoring=PPR&week=draft\"\n",
    "# K = \"https://www.fantasypros.com/nfl/projections/k.php?week=draft\"\n",
    "# DEF = \"https://www.fantasypros.com/nfl/projections/dst.php?week=draft\"\n",
    "\n",
    "# urls = [QB, RB, WR, TE, FLEX, K, DEF]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Make a get request\n",
    "# r = requests.get(url)\n",
    "\n",
    "# # Initialize soup object\n",
    "# soup = BeautifulSoup(r.text, \"html.parser\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Find the table\n",
    "# table = soup.find(\"table\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # print(table)\n",
    "\n",
    "# # Extract table data\n",
    "\n",
    "# # Extract headers\n",
    "# headers = []\n",
    "# for header in table.find_all(\"th\"):\n",
    "#     headers.append(header.get_text().strip())\n",
    "\n",
    "\n",
    "# # Extract rows\n",
    "# rows = []\n",
    "# for row in table.find_all(\"tr\"):\n",
    "#     cells = row.find_all(\"td\")\n",
    "#     cells = [cell.get_text().strip() for cell in cells]\n",
    "#     if cells:\n",
    "#         rows.append(cells)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Check if we can see the data\n",
    "\n",
    "# for header in headers:\n",
    "#     print(header, end=\" | \")\n",
    "# # print('\\n' + '-'*40)\n",
    "\n",
    "# for row in rows:\n",
    "#     print(\" | \".join(row))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(headers)\n",
    "# print(rows[1:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Save data as csv\n",
    "\n",
    "# rows = rows[1:]\n",
    "\n",
    "# with open(\"rb_projections\", \"w\") as file:\n",
    "#     writer = csv.writer(file)\n",
    "#     writer.writerow(headers)\n",
    "#     for row in rows:\n",
    "#         writer.writerow(row)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data = pd.read_csv(\"rb_projections\")\n",
    "\n",
    "# data.head(25)\n",
    "\n",
    "# # data.dtypes\n",
    "\n",
    "# data[\"YDS\"] = data[\"YDS\"].str.replace(\",\", \"\")\n",
    "# data[\"YDS\"] = pd.to_numeric(data[\"YDS\"], errors=\"coerce\")\n",
    "# data[\"YDS\"] = data[\"YDS\"].astype(\"float64\")\n",
    "\n",
    "# data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Overwrite the csv file with the new cleaned data\n",
    "\n",
    "# data.to_csv(\"rb_projections\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "fantasy_project",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
