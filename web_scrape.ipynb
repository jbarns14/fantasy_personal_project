{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import modules\n",
    "import os\n",
    "import requests\n",
    "import pandas as pd\n",
    "from bs4 import BeautifulSoup\n",
    "import csv\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a dictionary of URLs for each position group\n",
    "\n",
    "url_dict = {\n",
    "    \"QB\": \"https://www.fantasypros.com/nfl/projections/qb.php?week=draft\",\n",
    "    \"RB\": \"https://www.fantasypros.com/nfl/projections/rb.php?week=draft&scoring=PPR&week=draft\",\n",
    "    \"WR\": \"https://www.fantasypros.com/nfl/projections/wr.php?week=draft&scoring=PPR&week=draft\",\n",
    "    \"TE\": \"https://www.fantasypros.com/nfl/projections/te.php?week=draft&scoring=PPR&week=draft\",\n",
    "    \"FLEX\": \"https://www.fantasypros.com/nfl/projections/flex.php?week=draft&scoring=PPR&week=draft\",\n",
    "    \"K\": \"https://www.fantasypros.com/nfl/projections/k.php?week=draft\",\n",
    "    \"DEF\": \"https://www.fantasypros.com/nfl/projections/dst.php?week=draft\",\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data from QB (https://www.fantasypros.com/nfl/projections/qb.php?week=draft) saved to data/scraped/QB_projections.csv\n",
      "Data from RB (https://www.fantasypros.com/nfl/projections/rb.php?week=draft&scoring=PPR&week=draft) saved to data/scraped/RB_projections.csv\n",
      "Data from WR (https://www.fantasypros.com/nfl/projections/wr.php?week=draft&scoring=PPR&week=draft) saved to data/scraped/WR_projections.csv\n",
      "Data from TE (https://www.fantasypros.com/nfl/projections/te.php?week=draft&scoring=PPR&week=draft) saved to data/scraped/TE_projections.csv\n",
      "Data from FLEX (https://www.fantasypros.com/nfl/projections/flex.php?week=draft&scoring=PPR&week=draft) saved to data/scraped/FLEX_projections.csv\n",
      "Data from K (https://www.fantasypros.com/nfl/projections/k.php?week=draft) saved to data/scraped/K_projections.csv\n",
      "Data from DEF (https://www.fantasypros.com/nfl/projections/dst.php?week=draft) saved to data/scraped/DEF_projections.csv\n",
      "Scraping and data saving completed.\n"
     ]
    }
   ],
   "source": [
    "# Step 2: Loop through each key-value pair in the dictionary\n",
    "for name, url in url_dict.items():\n",
    "    response = requests.get(url)\n",
    "    soup = BeautifulSoup(response.text, \"html.parser\")\n",
    "\n",
    "    # Example: Locate and extract data from a table (customize this as needed)\n",
    "    table = soup.find(\"table\")\n",
    "\n",
    "    if table:\n",
    "        headers = [header.get_text().strip() for header in table.find_all(\"th\")]\n",
    "        rows = []\n",
    "        for row in table.find_all(\"tr\"):\n",
    "            cells = [cell.get_text().strip() for cell in row.find_all(\"td\")]\n",
    "            if cells:  # Only append non-empty rows\n",
    "                rows.append(cells)\n",
    "\n",
    "        # Combine headers and rows into a DataFrame\n",
    "        df = pd.DataFrame(rows, columns=headers)\n",
    "\n",
    "        # Step 3: Save each DataFrame to a separate CSV file with the variable name\n",
    "        filename = os.path.join(\"data/scraped\", f\"{name}_projections.csv\")\n",
    "        df.to_csv(filename, index=False)\n",
    "\n",
    "        print(f\"Data from {name} ({url}) saved to {filename}\")\n",
    "\n",
    "print(\"Scraping and data saving completed.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data from data/scraped/QB_projections.csv cleaned and saved to data/clean/QB_projections_clean.csv\n",
      "Data from data/scraped/RB_projections.csv cleaned and saved to data/clean/RB_projections_clean.csv\n",
      "Data from data/scraped/WR_projections.csv cleaned and saved to data/clean/WR_projections_clean.csv\n",
      "Data from data/scraped/TE_projections.csv cleaned and saved to data/clean/TE_projections_clean.csv\n",
      "Data from data/scraped/K_projections.csv cleaned and saved to data/clean/K_projections_clean.csv\n",
      "Data from data/scraped/DEF_projections.csv cleaned and saved to data/clean/DEF_projections_clean.csv\n",
      "All data merged and saved to data/clean/all_projections_clean.csv\n",
      "Data cleaning completed.\n"
     ]
    }
   ],
   "source": [
    "# Clean the data so it can be manipulated\n",
    "\n",
    "# Some of the positions have an extra row of column headers that need to be deleted\n",
    "\n",
    "clean_files = [\n",
    "    \"QB_projections\",\n",
    "    \"RB_projections\",\n",
    "    \"WR_projections\",\n",
    "    \"TE_projections\",\n",
    "    \"FLEX_projections\",\n",
    "    \"K_projections\",\n",
    "    \"DEF_projections\",\n",
    "]\n",
    "\n",
    "# Position mapping for each file\n",
    "position_mapping = {\n",
    "    \"QB_projections\": \"QB\",\n",
    "    \"RB_projections\": \"RB\",\n",
    "    \"WR_projections\": \"WR\",\n",
    "    \"TE_projections\": \"TE\",\n",
    "    \"K_projections\": \"K\",\n",
    "    \"DEF_projections\": \"DEF\",\n",
    "}\n",
    "\n",
    "# List to store each cleaned dataframe in order to merge them into one final one at the end\n",
    "dfs = []\n",
    "\n",
    "for file in clean_files:\n",
    "    df = pd.read_csv(f\"data/scraped/{file}.csv\")\n",
    "\n",
    "    # Make sure all columns after the 'Player' column are numerical\n",
    "    df.iloc[:, 2:] = (\n",
    "        df.iloc[:, 2:]\n",
    "        .replace({\",\": \"\"}, regex=True)\n",
    "        .apply(pd.to_numeric, errors=\"coerce\")\n",
    "        .astype(float)\n",
    "    )\n",
    "\n",
    "    if file == \"RB_projections\":\n",
    "        df = df[1:]\n",
    "        df = df.rename(\n",
    "            columns={\n",
    "                \"ATT\": \"RUSH_ATT\",\n",
    "                \"YDS\": \"RUSH_YDS\",\n",
    "                \"TDS\": \"RUSH_TDS\",\n",
    "                \"YDS.1\": \"REC_YDS\",\n",
    "                \"TDS.1\": \"REC_TDS\",\n",
    "            }\n",
    "        )\n",
    "    elif file == \"WR_projections\":\n",
    "        df = df[1:]\n",
    "        df = df.rename(\n",
    "            columns={\n",
    "                \"YDS\": \"REC_YDS\",\n",
    "                \"TDS\": \"REC_TDS\",\n",
    "                \"YDS.1\": \"RUSH_YDS\",\n",
    "                \"TDS.1\": \"RUSH_TDS\",\n",
    "            }\n",
    "        )\n",
    "    elif file == \"TE_projections\":\n",
    "        df = df[1:]\n",
    "        df = df.rename(columns={\"YDS\": \"REC_YDS\", \"TDS\": \"REC_TDS\"})\n",
    "\n",
    "    elif file == \"QB_projections\":\n",
    "        df = df[1:]\n",
    "        df = df.rename(\n",
    "            columns={\n",
    "                \"YDS\": \"PASS_YDS\",\n",
    "                \"TDS\": \"PASS_TDS\",\n",
    "                \"ATT.1\": \"RUSH_ATT\",\n",
    "                \"YDS.1\": \"RUSH_YDS\",\n",
    "                \"TDS.1\": \"RUSH_TDS\",\n",
    "            }\n",
    "        )\n",
    "\n",
    "    elif file == \"FLEX_projections\":\n",
    "        df = df[1:]\n",
    "        df = df.rename(\n",
    "            columns={\n",
    "                \"YDS\": \"RUSH_YDS\",\n",
    "                \"TDS\": \"RUSH_TDS\",\n",
    "                \"YDS.1\": \"REC_YDS\",\n",
    "                \"TDS.1\": \"REC_TDS\",\n",
    "            }\n",
    "        )\n",
    "        df[\"POS\"] = df[\"POS\"].astype(str).apply(lambda x: re.sub(r\"[^a-zA-Z]\", \"\", x))\n",
    "\n",
    "        # Continue to the next file without appending FLEX to dfs\n",
    "        continue\n",
    "\n",
    "    # Assign position based on the filename using position_mapping\n",
    "    pos = position_mapping[file]\n",
    "    df[\"POS\"] = pos\n",
    "\n",
    "    # Append the cleaned DataFrame to the list\n",
    "    dfs.append(df)\n",
    "\n",
    "    # Save cleaned files to the clean subdirectory\n",
    "    filename = os.path.join(\"data/clean\", f\"{file}_clean.csv\")\n",
    "    df.to_csv(filename, index=False)\n",
    "\n",
    "    print(f\"Data from data/scraped/{file}.csv cleaned and saved to {filename}\")\n",
    "\n",
    "# Concatenate all DataFrames in the list into one\n",
    "final_df = pd.concat(dfs, ignore_index=True)\n",
    "\n",
    "# Move 'POS' column to be the second column\n",
    "columns = final_df.columns.tolist()\n",
    "if \"POS\" in columns:\n",
    "    columns.insert(1, columns.pop(columns.index(\"POS\")))\n",
    "    final_df = final_df[columns]\n",
    "\n",
    "\n",
    "# Optionally, save the final merged DataFrame to a CSV file\n",
    "final_filename = os.path.join(\"data/clean\", \"all_projections_clean.csv\")\n",
    "final_df.to_csv(final_filename, index=False)\n",
    "\n",
    "print(f\"All data merged and saved to {final_filename}\")\n",
    "\n",
    "print(\"Data cleaning completed.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Player       object\n",
      "POS          object\n",
      "ATT         float64\n",
      "CMP         float64\n",
      "PASS_YDS    float64\n",
      "PASS_TDS    float64\n",
      "INTS        float64\n",
      "RUSH_ATT    float64\n",
      "RUSH_YDS    float64\n",
      "RUSH_TDS    float64\n",
      "FL          float64\n",
      "FPTS        float64\n",
      "REC         float64\n",
      "REC_YDS     float64\n",
      "REC_TDS     float64\n",
      "FG          float64\n",
      "FGA         float64\n",
      "XPT         float64\n",
      "SACK        float64\n",
      "INT         float64\n",
      "FR          float64\n",
      "FF          float64\n",
      "TD          float64\n",
      "SAFETY      float64\n",
      "PA          float64\n",
      "YDS AGN     float64\n",
      "dtype: object\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Player</th>\n",
       "      <th>POS</th>\n",
       "      <th>ATT</th>\n",
       "      <th>CMP</th>\n",
       "      <th>PASS_YDS</th>\n",
       "      <th>PASS_TDS</th>\n",
       "      <th>INTS</th>\n",
       "      <th>RUSH_ATT</th>\n",
       "      <th>RUSH_YDS</th>\n",
       "      <th>RUSH_TDS</th>\n",
       "      <th>...</th>\n",
       "      <th>FGA</th>\n",
       "      <th>XPT</th>\n",
       "      <th>SACK</th>\n",
       "      <th>INT</th>\n",
       "      <th>FR</th>\n",
       "      <th>FF</th>\n",
       "      <th>TD</th>\n",
       "      <th>SAFETY</th>\n",
       "      <th>PA</th>\n",
       "      <th>YDS AGN</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Jalen Hurts PHI</td>\n",
       "      <td>QB</td>\n",
       "      <td>520.2</td>\n",
       "      <td>339.7</td>\n",
       "      <td>3810.4</td>\n",
       "      <td>24.4</td>\n",
       "      <td>12.1</td>\n",
       "      <td>145.3</td>\n",
       "      <td>624.2</td>\n",
       "      <td>11.3</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Josh Allen BUF</td>\n",
       "      <td>QB</td>\n",
       "      <td>564.7</td>\n",
       "      <td>368.0</td>\n",
       "      <td>4060.0</td>\n",
       "      <td>27.8</td>\n",
       "      <td>14.0</td>\n",
       "      <td>108.2</td>\n",
       "      <td>556.7</td>\n",
       "      <td>8.9</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Lamar Jackson BAL</td>\n",
       "      <td>QB</td>\n",
       "      <td>463.6</td>\n",
       "      <td>303.7</td>\n",
       "      <td>3567.1</td>\n",
       "      <td>25.0</td>\n",
       "      <td>10.6</td>\n",
       "      <td>146.1</td>\n",
       "      <td>836.1</td>\n",
       "      <td>5.4</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Patrick Mahomes II KC</td>\n",
       "      <td>QB</td>\n",
       "      <td>584.8</td>\n",
       "      <td>392.2</td>\n",
       "      <td>4371.2</td>\n",
       "      <td>32.7</td>\n",
       "      <td>11.2</td>\n",
       "      <td>72.0</td>\n",
       "      <td>376.4</td>\n",
       "      <td>1.8</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Anthony Richardson IND</td>\n",
       "      <td>QB</td>\n",
       "      <td>511.7</td>\n",
       "      <td>325.6</td>\n",
       "      <td>3503.9</td>\n",
       "      <td>20.0</td>\n",
       "      <td>11.4</td>\n",
       "      <td>127.6</td>\n",
       "      <td>646.0</td>\n",
       "      <td>7.9</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 26 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                   Player POS    ATT    CMP  PASS_YDS  PASS_TDS  INTS  \\\n",
       "0         Jalen Hurts PHI  QB  520.2  339.7    3810.4      24.4  12.1   \n",
       "1          Josh Allen BUF  QB  564.7  368.0    4060.0      27.8  14.0   \n",
       "2       Lamar Jackson BAL  QB  463.6  303.7    3567.1      25.0  10.6   \n",
       "3   Patrick Mahomes II KC  QB  584.8  392.2    4371.2      32.7  11.2   \n",
       "4  Anthony Richardson IND  QB  511.7  325.6    3503.9      20.0  11.4   \n",
       "\n",
       "   RUSH_ATT  RUSH_YDS  RUSH_TDS  ...  FGA  XPT  SACK  INT  FR  FF  TD  SAFETY  \\\n",
       "0     145.3     624.2      11.3  ...  NaN  NaN   NaN  NaN NaN NaN NaN     NaN   \n",
       "1     108.2     556.7       8.9  ...  NaN  NaN   NaN  NaN NaN NaN NaN     NaN   \n",
       "2     146.1     836.1       5.4  ...  NaN  NaN   NaN  NaN NaN NaN NaN     NaN   \n",
       "3      72.0     376.4       1.8  ...  NaN  NaN   NaN  NaN NaN NaN NaN     NaN   \n",
       "4     127.6     646.0       7.9  ...  NaN  NaN   NaN  NaN NaN NaN NaN     NaN   \n",
       "\n",
       "   PA  YDS AGN  \n",
       "0 NaN      NaN  \n",
       "1 NaN      NaN  \n",
       "2 NaN      NaN  \n",
       "3 NaN      NaN  \n",
       "4 NaN      NaN  \n",
       "\n",
       "[5 rows x 26 columns]"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(\"data/clean/all_projections_clean.csv\")\n",
    "print(df.dtypes)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "259    1441.3\n",
       "Name: REC_YDS, dtype: float64"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[df[\"Player\"] == \"Justin Jefferson MIN\"][\"REC_YDS\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # URLs to scrape from\n",
    "\n",
    "# QB = \"https://www.fantasypros.com/nfl/projections/qb.php?week=draft\"\n",
    "# RB = \"https://www.fantasypros.com/nfl/projections/rb.php?week=draft&scoring=PPR&week=draft\"\n",
    "# WR = \"https://www.fantasypros.com/nfl/projections/wr.php?week=draft&scoring=PPR&week=draft\"\n",
    "# TE = \"https://www.fantasypros.com/nfl/projections/te.php?week=draft&scoring=PPR&week=draft\"\n",
    "# FLEX = \"https://www.fantasypros.com/nfl/projections/flex.php?week=draft&scoring=PPR&week=draft\"\n",
    "# K = \"https://www.fantasypros.com/nfl/projections/k.php?week=draft\"\n",
    "# DEF = \"https://www.fantasypros.com/nfl/projections/dst.php?week=draft\"\n",
    "\n",
    "# urls = [QB, RB, WR, TE, FLEX, K, DEF]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Make a get request\n",
    "# r = requests.get(url)\n",
    "\n",
    "# # Initialize soup object\n",
    "# soup = BeautifulSoup(r.text, \"html.parser\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Find the table\n",
    "# table = soup.find(\"table\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # print(table)\n",
    "\n",
    "# # Extract table data\n",
    "\n",
    "# # Extract headers\n",
    "# headers = []\n",
    "# for header in table.find_all(\"th\"):\n",
    "#     headers.append(header.get_text().strip())\n",
    "\n",
    "\n",
    "# # Extract rows\n",
    "# rows = []\n",
    "# for row in table.find_all(\"tr\"):\n",
    "#     cells = row.find_all(\"td\")\n",
    "#     cells = [cell.get_text().strip() for cell in cells]\n",
    "#     if cells:\n",
    "#         rows.append(cells)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Check if we can see the data\n",
    "\n",
    "# for header in headers:\n",
    "#     print(header, end=\" | \")\n",
    "# # print('\\n' + '-'*40)\n",
    "\n",
    "# for row in rows:\n",
    "#     print(\" | \".join(row))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(headers)\n",
    "# print(rows[1:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Save data as csv\n",
    "\n",
    "# rows = rows[1:]\n",
    "\n",
    "# with open(\"rb_projections\", \"w\") as file:\n",
    "#     writer = csv.writer(file)\n",
    "#     writer.writerow(headers)\n",
    "#     for row in rows:\n",
    "#         writer.writerow(row)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data = pd.read_csv(\"rb_projections\")\n",
    "\n",
    "# data.head(25)\n",
    "\n",
    "# # data.dtypes\n",
    "\n",
    "# data[\"YDS\"] = data[\"YDS\"].str.replace(\",\", \"\")\n",
    "# data[\"YDS\"] = pd.to_numeric(data[\"YDS\"], errors=\"coerce\")\n",
    "# data[\"YDS\"] = data[\"YDS\"].astype(\"float64\")\n",
    "\n",
    "# data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Overwrite the csv file with the new cleaned data\n",
    "\n",
    "# data.to_csv(\"rb_projections\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "fantasy_project",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
