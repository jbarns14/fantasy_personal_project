{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import modules\n",
    "import os\n",
    "import requests\n",
    "import pandas as pd\n",
    "from bs4 import BeautifulSoup\n",
    "import csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data from QB (https://www.fantasypros.com/nfl/projections/qb.php?week=draft) saved to data/scraped/QB_projections.csv\n",
      "Data from RB (https://www.fantasypros.com/nfl/projections/rb.php?week=draft&scoring=PPR&week=draft) saved to data/scraped/RB_projections.csv\n",
      "Data from WR (https://www.fantasypros.com/nfl/projections/wr.php?week=draft&scoring=PPR&week=draft) saved to data/scraped/WR_projections.csv\n",
      "Data from TE (https://www.fantasypros.com/nfl/projections/te.php?week=draft&scoring=PPR&week=draft) saved to data/scraped/TE_projections.csv\n",
      "Data from FLEX (https://www.fantasypros.com/nfl/projections/flex.php?week=draft&scoring=PPR&week=draft) saved to data/scraped/FLEX_projections.csv\n",
      "Data from K (https://www.fantasypros.com/nfl/projections/k.php?week=draft) saved to data/scraped/K_projections.csv\n",
      "Data from DEF (https://www.fantasypros.com/nfl/projections/dst.php?week=draft) saved to data/scraped/DEF_projections.csv\n",
      "Scraping and data saving completed.\n"
     ]
    }
   ],
   "source": [
    "# Try multiplying the process for each position group\n",
    "\n",
    "url_dict = {\n",
    "    \"QB\": \"https://www.fantasypros.com/nfl/projections/qb.php?week=draft\",\n",
    "    \"RB\": \"https://www.fantasypros.com/nfl/projections/rb.php?week=draft&scoring=PPR&week=draft\",\n",
    "    \"WR\": \"https://www.fantasypros.com/nfl/projections/wr.php?week=draft&scoring=PPR&week=draft\",\n",
    "    \"TE\": \"https://www.fantasypros.com/nfl/projections/te.php?week=draft&scoring=PPR&week=draft\",\n",
    "    \"FLEX\": \"https://www.fantasypros.com/nfl/projections/flex.php?week=draft&scoring=PPR&week=draft\",\n",
    "    \"K\": \"https://www.fantasypros.com/nfl/projections/k.php?week=draft\",\n",
    "    \"DEF\": \"https://www.fantasypros.com/nfl/projections/dst.php?week=draft\",\n",
    "}\n",
    "\n",
    "# Step 2: Loop through each key-value pair in the dictionary\n",
    "for name, url in url_dict.items():\n",
    "    response = requests.get(url)\n",
    "    soup = BeautifulSoup(response.text, \"html.parser\")\n",
    "\n",
    "    # Example: Locate and extract data from a table (customize this as needed)\n",
    "    table = soup.find(\"table\")\n",
    "\n",
    "    if table:\n",
    "        headers = [header.get_text().strip() for header in table.find_all(\"th\")]\n",
    "        rows = []\n",
    "        for row in table.find_all(\"tr\"):\n",
    "            cells = [cell.get_text().strip() for cell in row.find_all(\"td\")]\n",
    "            if cells:  # Only append non-empty rows\n",
    "                rows.append(cells)\n",
    "\n",
    "        # Combine headers and rows into a DataFrame\n",
    "        df = pd.DataFrame(rows, columns=headers)\n",
    "\n",
    "        # Step 3: Save each DataFrame to a separate CSV file with the variable name\n",
    "        filename = os.path.join(\"data/scraped\", f\"{name}_projections.csv\")\n",
    "        df.to_csv(filename, index=False)\n",
    "\n",
    "        print(f\"Data from {name} ({url}) saved to {filename}\")\n",
    "\n",
    "print(\"Scraping and data saving completed.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# URLs to scrape from\n",
    "\n",
    "QB = \"https://www.fantasypros.com/nfl/projections/qb.php?week=draft\"\n",
    "RB = \"https://www.fantasypros.com/nfl/projections/rb.php?week=draft&scoring=PPR&week=draft\"\n",
    "WR = \"https://www.fantasypros.com/nfl/projections/wr.php?week=draft&scoring=PPR&week=draft\"\n",
    "TE = \"https://www.fantasypros.com/nfl/projections/te.php?week=draft&scoring=PPR&week=draft\"\n",
    "FLEX = \"https://www.fantasypros.com/nfl/projections/flex.php?week=draft&scoring=PPR&week=draft\"\n",
    "K = \"https://www.fantasypros.com/nfl/projections/k.php?week=draft\"\n",
    "DEF = \"https://www.fantasypros.com/nfl/projections/dst.php?week=draft\"\n",
    "\n",
    "urls = [QB, RB, WR, TE, FLEX, K, DEF]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Make a get request\n",
    "# r = requests.get(url)\n",
    "\n",
    "# # Initialize soup object\n",
    "# soup = BeautifulSoup(r.text, \"html.parser\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Find the table\n",
    "# table = soup.find(\"table\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # print(table)\n",
    "\n",
    "# # Extract table data\n",
    "\n",
    "# # Extract headers\n",
    "# headers = []\n",
    "# for header in table.find_all(\"th\"):\n",
    "#     headers.append(header.get_text().strip())\n",
    "\n",
    "\n",
    "# # Extract rows\n",
    "# rows = []\n",
    "# for row in table.find_all(\"tr\"):\n",
    "#     cells = row.find_all(\"td\")\n",
    "#     cells = [cell.get_text().strip() for cell in cells]\n",
    "#     if cells:\n",
    "#         rows.append(cells)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Check if we can see the data\n",
    "\n",
    "# for header in headers:\n",
    "#     print(header, end=\" | \")\n",
    "# # print('\\n' + '-'*40)\n",
    "\n",
    "# for row in rows:\n",
    "#     print(\" | \".join(row))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(headers)\n",
    "# print(rows[1:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Save data as csv\n",
    "\n",
    "# rows = rows[1:]\n",
    "\n",
    "# with open(\"rb_projections\", \"w\") as file:\n",
    "#     writer = csv.writer(file)\n",
    "#     writer.writerow(headers)\n",
    "#     for row in rows:\n",
    "#         writer.writerow(row)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data = pd.read_csv(\"rb_projections\")\n",
    "\n",
    "# data.head(25)\n",
    "\n",
    "# # data.dtypes\n",
    "\n",
    "# data[\"YDS\"] = data[\"YDS\"].str.replace(\",\", \"\")\n",
    "# data[\"YDS\"] = pd.to_numeric(data[\"YDS\"], errors=\"coerce\")\n",
    "# data[\"YDS\"] = data[\"YDS\"].astype(\"float64\")\n",
    "\n",
    "# data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'data' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[11], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# Overwrite the csv file with the new cleaned data\u001b[39;00m\n\u001b[0;32m----> 3\u001b[0m \u001b[43mdata\u001b[49m\u001b[38;5;241m.\u001b[39mto_csv(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrb_projections\u001b[39m\u001b[38;5;124m\"\u001b[39m, index\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'data' is not defined"
     ]
    }
   ],
   "source": [
    "# # Overwrite the csv file with the new cleaned data\n",
    "\n",
    "# data.to_csv(\"rb_projections\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "fantasy_project",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
